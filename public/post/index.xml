<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Beachgeek blog - a refuge for pineapple on pizza lovers</title>
    <link>https://blog.beachgeek.co.uk/post/</link>
    <description>Recent content in Posts on Beachgeek blog - a refuge for pineapple on pizza lovers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Nov 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://blog.beachgeek.co.uk/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Adding Amazon Bedrock Llama2 as an assistant in Ragna</title>
      <link>https://blog.beachgeek.co.uk/adding-llama2-to-ragna/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/adding-llama2-to-ragna/</guid>
      <description>Adding a new assistant in Ragna Following up from my previous post on Ragna, I wanted to share following the announcement of Meta&amp;rsquo;s Llama2 13b model availability within Amazon Bedrock, how you can incorporate that.&#xA;I have also put together a GitHub repo that shares the code, something that I got quite a few questions from the original post.&#xA;Adding Meta&amp;rsquo;s Llama2&#xA;As with adding Amazon Bedrock&amp;rsquo;s Anthropic&amp;rsquo;s Claude support, it was pretty straight forward to modify the original code to add support for Llama2.</description>
    </item>
    <item>
      <title>Unboxing Ragna: Getting hands on and making it to work with Amazon Bedrock</title>
      <link>https://blog.beachgeek.co.uk/getting-started-with-ragna/</link>
      <pubDate>Sun, 12 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/getting-started-with-ragna/</guid>
      <description>Unboxing Ragna: Getting hands on and making it to work with Amazon Bedrock I am always on the look out for interesting new projects to check out, and this week I came across Ragna, an open source Retrieval Augmented Generation RAG orchestration framework. It is a new project with a committed and active community, so I wanted to find out more about this project.&#xA;What piqued my interest was reading this blog post, Unveiling Ragna: An Open Source RAG-based AI Orchestration Framework Designed to Scale From Research to Production which takes a look at the background, or as I like to think of it, the &amp;ldquo;scratch that needed to be itched&amp;rdquo;.</description>
    </item>
    <item>
      <title>Getting gnarly with AI - a quick look at Griptape, an enterprise ready alternative to LangChain</title>
      <link>https://blog.beachgeek.co.uk/getting-started-with-griptape/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/getting-started-with-griptape/</guid>
      <description>Getting started with Griptape Getting gnarly with AI&#xA;When I was much much younger, I was known to (very occasionally) drop an ollie, kick-turn, or very occasionally dare a drop in on my trusty skateboard. Thanks to the grip tape, my shoes would stick to the board, and gave me the confidence I could try these tricks. I was always grateful to that grip tape and who knew all these years later, I would become re-aquatinted with it (albeit in a different form!</description>
    </item>
    <item>
      <title>Using Amazon CodeWhisperer as my scripting sidekick</title>
      <link>https://blog.beachgeek.co.uk/code-whisperer-my-trusted-sidekick/</link>
      <pubDate>Mon, 04 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/code-whisperer-my-trusted-sidekick/</guid>
      <description>How are you using these new AI coding assistants like Amazon CodeWhisperer? I want to share a quick story about how I am finding some success with using these tools, which I hope will encourage you to experiment for yourselves.&#xA;As I work on new projects, demos, blog posts, I often need to do supporting activities such as creating or cleaning up AWS environments, which I sometimes do by hand but mostly do via the AWS CLI or via Python scripts and boto3.</description>
    </item>
    <item>
      <title>A look at airflowctl, a tool to help you manage Apache Airflow projects</title>
      <link>https://blog.beachgeek.co.uk/airflowctl-first-look/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/airflowctl-first-look/</guid>
      <description>I have written in the past about setting up developer environments and tools when working with Apache Airflow. Today I came across a new tool from Kaxil Naik, directory of engineering at Astronomer and all round Apache Airflow good guy. Kaxil has put together airflowctl, a command-line tool for managing Apache Airflow™ projects, and making it super easy to get up and running. What does it do? Well, it helps you install and use different versions of Apache Airflow, work with Variables and Connections, provide live logs, and more.</description>
    </item>
    <item>
      <title>Deploying a serverless web analytics solution for your websites</title>
      <link>https://blog.beachgeek.co.uk/deploying-open-source-clickstream-analytics/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/deploying-open-source-clickstream-analytics/</guid>
      <description>Update, August 1st&#xA;I have been running this project for five weeks now, so have a better understanding of costs. My bill in July was $0.85, and I suspect this will be reasonably stable over the coming months. I think this represents great value! I will report back at the end of the year and update this&#xA;Like many folk, I run a personal blog. This blog runs Hugo and turns my markdown pages into static content, which I then deploy on Netlify.</description>
    </item>
    <item>
      <title>Integrating Keycloak as my Identity Provider for IAM Identity Centre: Part two, configuring Keycloak as my Identity provider</title>
      <link>https://blog.beachgeek.co.uk/keycloak-on-aws-part-two/</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/keycloak-on-aws-part-two/</guid>
      <description>This is the follow up post to Integrating Keycloak as my Identity Provider for IAM Identity Centre: Part one, deploying Keycloak on AWS, where I looked at how to deploy Keycloak on AWS in order to have an Identity Provider to use when configuring AWS Identity Centre. In this post, I am going to use that setup, and show you how I configured it to integrate with AWS Identity Centre to provide access to my AWS resources.</description>
    </item>
    <item>
      <title>Using CDK to deploy AWS managed Active Directory</title>
      <link>https://blog.beachgeek.co.uk/active-directory-using-cdk/</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/active-directory-using-cdk/</guid>
      <description>CIFS (Common Internet File System) and SMB (Server Message Block) are both Windows file-sharing protocols used in storage systems. As part of a new demo/blog post that looks at how to use data stored on SMB/CIF file shares with Apache Airflow, I have been exploring the various options of creating SMB/CIF compatible resources. (There are LOTS of ways you could do this, so there is plenty for me to play around with!</description>
    </item>
    <item>
      <title>Integrating Keycloak as my Identity Provider for IAM Identity Centre: Part one, deploying Keycloak on AWS</title>
      <link>https://blog.beachgeek.co.uk/keycloak-on-aws-part-one/</link>
      <pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/keycloak-on-aws-part-one/</guid>
      <description>Integrating Keycloak as my Identity Provider for IAM Identity Centre: Part one, deploying Keycloak on AWS &amp;ldquo;It was the best of times, it was the worst of times&amp;hellip;&amp;rdquo; A Tale of Two Cities&#xA;It started out innocently enough. As part of working on a new blog post, I needed a way to use an open source tool called saml2aws that generates AWS short lived credentials that you can use to access your AWS resources.</description>
    </item>
    <item>
      <title>Exploring Shell Launch Scripts on Managed Workflows for Apache Airflow (MWAA) and mwaa-local-runner</title>
      <link>https://blog.beachgeek.co.uk/mwaa-startup-scripts/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/mwaa-startup-scripts/</guid>
      <description>Managed Workflows for Apache Airflow (MWAA) recently launched a new feature that a lot of folk had been asking for, which was the ability to add additional libraries, binaries, or environment variables when launching Airflow workers. If you missed the announcement, Amazon MWAA now supports Shell Launch Scripts, this new capability allows you to easily do this by creating a script and then configuring your MWAA environments to use that script during the start-up phase.</description>
    </item>
    <item>
      <title>Getting mwaa-local-runner up on AWS Cloud9</title>
      <link>https://blog.beachgeek.co.uk/mwaa-local-runner-on-c9/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/mwaa-local-runner-on-c9/</guid>
      <description>Here is a quick recipe if you are looking to get mwaa-local-runner up and running on your Cloud9 developer setup. This might not be the most optimised way, so I am very happy to received suggestions on how to improve this. What I will cover here is how to deploy mwaa-local-runner onto a standard Cloud9 IDE, deployed in a default VPC.&#xA;Updating my AWS Cloud9 environment&#xA;The first thing I needed to do was to increase the size of my local disk as Cloud9 only provides 10gb of storage.</description>
    </item>
    <item>
      <title>Working with Managed Workflows for Apache Airflow (MWAA) and Amazon Redshift </title>
      <link>https://blog.beachgeek.co.uk/using-redshift-with-mwaa/</link>
      <pubDate>Fri, 07 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/using-redshift-with-mwaa/</guid>
      <description>Working with Managed Workflows for Apache Airflow (MWAA) and Amazon Redshift I was recently looking at some Stack Overflow questions from the AWS Collective and saw a number of folk having questions about the integration between Amazon Redshift and Managed Workflows for Apache Airflow (MWAA). I thought I would put together a quick post that might help folk address what I saw were some of the common challenges.&#xA;There is some code that accompanies this post, which you can find at the GitHub repository cdk-mwaa-redshift.</description>
    </item>
    <item>
      <title>Self managed Apache Airflow with Data on EKS</title>
      <link>https://blog.beachgeek.co.uk/self-managed-apache-airflow-using-doeks/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/self-managed-apache-airflow-using-doeks/</guid>
      <description>I have written in the past about how you can get started with Apache Airflow using the AWS managed service, Managed Workflows for Apache Airflow. But what if you want to self managed Apache Airflow? When I speak with developers, there are sometimes reasons why a managed service might not fit their needs. Some of the common things that come up include:&#xA;whether you need the increase level of access, a greater level of control of the configuration of Apache Airflow have the need to have the very latest versions or features of Apache Airflow if you have the need to run workflows that use more resources that managed services provide (for example, need significant compute) Total Cost Ownership One thing to consider when assessing managed vs self managed is the cost of the managed service against the total costs of you having to do the same thing.</description>
    </item>
    <item>
      <title>VSCode and Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/using-vscode-with-airflow/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/using-vscode-with-airflow/</guid>
      <description>VSCode and Apache Airflow In this short post, I wanted to highlight how you can use a VSCode plugin to work with a local running instance of Apache Airflow to improve the developer experience. This post was inspired by a tweet from Kaxil Naik who was asking about what features developers are looking for when using VSCode and Pycharm and Apache Airflow.&#xA;In this post I will show you how you can configure mwaa-local-runner, an open source project that provides you with an easy way to get a local Apache Airflow environment up and running (that is configuration wide, aligned to the Amazon Managed Workflows for Apache Airflow service MWAA), together with some VSCode plugins.</description>
    </item>
    <item>
      <title>sbomqs, an open source tool to quality check your SBOMS</title>
      <link>https://blog.beachgeek.co.uk/sbomqs-an-open-source-tool-to-qa-sboms/</link>
      <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/sbomqs-an-open-source-tool-to-qa-sboms/</guid>
      <description>When putting together a previous post on how to use open source tools to create a software bill of materials (SBOM), Ritesh Noronha alerted me to another project, sbomqs that aims to simplify the evaluation of SBOM quality for both producers and consumers. A quality SBOM is one that is accurate, complete, and up-to-date. It should accurately reflect the components and dependencies used in the software application, including their version and optionally any known vulnerabilities.</description>
    </item>
    <item>
      <title>Building a software bill of materials (SBOM) using open source tools</title>
      <link>https://blog.beachgeek.co.uk/building-sbom-with-syft/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/building-sbom-with-syft/</guid>
      <description>This is the second post exploring how you can use open source tools to help you build a stronger defence against common software supply chain attacks. In this blog post, I look at syft, an open source CLI tool and Go library for generating a Software Bill of Materials (SBOM) from container images and filesystems. We will use examples and build on the previous post, Getting hands on with Sigstore Cosign on AWS.</description>
    </item>
    <item>
      <title>Getting hands on with Sigstore Cosign on AWS</title>
      <link>https://blog.beachgeek.co.uk/getting-hands-on-with-sigstore-cosign-on-aws/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/getting-hands-on-with-sigstore-cosign-on-aws/</guid>
      <description>Getting hands on with Sigstore Cosign on AWS I am currently putting together some content around how you can use a number of open source tools to help build a stronger defence against common software supply chain attacks. In this blog post, I look at emerging tools from Sigstore, and focus in this post on Cosign, a tool that supports container image signing, verification, and storage in an Open Container Initiative (OCI) registry.</description>
    </item>
    <item>
      <title>Configuring the KubernetesPodOperator on Managed Workflows for Apache Airflow (MWAA) - non OIDC Amazon EKS Clusters</title>
      <link>https://blog.beachgeek.co.uk/mwaa-eks-no-oidc/</link>
      <pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/mwaa-eks-no-oidc/</guid>
      <description>Configuring the KubernetesPodOperator on Managed Workflows for Apache Airflow (MWAA) - non OIDC Amazon EKS Clusters Today I came across an interesting question around the use of the KubernetesPodOperator working on EKS Clusters where you have not configured OIDC. They had followed my blog post, and when it came to running the DAG, they got the following error:&#xA;[2023-01-26, 13:03:18 UTC] {{kubernetes_pod.py:566}} INFO - Creating pod mwaa-pod-test.0ab20a7075b84175b2a9a3fe32796f53 with labels: {&#39;dag_id&#39;: &#39;kubernetes_pod_example_iam_authenticator&#39;, &#39;task_id&#39;: &#39;pod-task&#39;, &#39;execution_date&#39;: &#39;2023-01-26T130310.</description>
    </item>
    <item>
      <title>Running the KubernetesPodOperator in different AWS accounts when using Amazon Managed Workflows for Apache Airflow v2.x</title>
      <link>https://blog.beachgeek.co.uk/mwaa-eks-multi-aws/</link>
      <pubDate>Mon, 09 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/mwaa-eks-multi-aws/</guid>
      <description>Running KubernetesPodOperator in different AWS accounts update August, 14th&#xA;I wanted to update to newer version of MWAA, so I have tested the original blog post against EKS 1.24 and MWAA version 2.4.3. I also had a few messages about whether this would work across different AWS regions. The good news is that it does. I have also put together a repo for this here&#xA;I thought that I would also check/update that it works for newer versions of MWAA, so I had 2.</description>
    </item>
    <item>
      <title>Experimenting with digital lanyards - introducing the Badger2040</title>
      <link>https://blog.beachgeek.co.uk/creating-digital-lanyards/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/creating-digital-lanyards/</guid>
      <description>Experimenting with digital lanyards As someone who attends events on a regular basis, I have spent a fair bit of time over the years looking at interesting ways to engage with attendees. One of the problems I was looking to solve was how do I share useful information with attendees without having to interrupt the conversations (something that typically happens as I try and find those links on my mobile phone).</description>
    </item>
    <item>
      <title>Contributing to the Apache Airflow project - Part Two</title>
      <link>https://blog.beachgeek.co.uk/contributing-to-the-apache-airflow-project-part-two/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/contributing-to-the-apache-airflow-project-part-two/</guid>
      <description>This is the second and concluding post providing an overview of the experience and journey contributing to the Apache Airflow project. You can catch Part One here.&#xA;Contributing to Apache Airflow - Part Deux In Part One of this series, we took our first steps in contributing to the Apache Airflow project. With a little bit more knowledge and experience, our first interactions with the Airflow community, we are ready to start exploring how the code works and see how we might go about fixing this.</description>
    </item>
    <item>
      <title>Orchestrating hybrid workflows using Amazon Managed Workflows for Apache Airflow (MWAA)</title>
      <link>https://blog.beachgeek.co.uk/orchestrating-hybrid-workflows-with-apache-airflow/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/orchestrating-hybrid-workflows-with-apache-airflow/</guid>
      <description>Using Apache Airflow to orchestrate hybrid workflows In some recent discussions with customers, the topic of how open source is increasingly being used as a common mechanisms to help build re-usable solutions that can protect investments in engineering and development time, skills and that work across on premises and Cloud environment. In 2021 my most viewed blog post talked about how you can build and deploy containerised applications, anywhere (Cloud, your data centre, other Clouds) and on anything (Intel and Arm).</description>
    </item>
    <item>
      <title>Contributing to the Apache Airflow project - Part One</title>
      <link>https://blog.beachgeek.co.uk/contributing-to-the-apache-airflow-project-part-one/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/contributing-to-the-apache-airflow-project-part-one/</guid>
      <description>Contributing to Apache Airflow Introduction In this series of posts, I am going to share what I learn as embark on my first upstream contribution to the Apache Airflow project. The purpose is to show you how typical open source projects like Apache Airflow work, how you engage with the community to orchestrate change and hopefully inspire more people to contribute to this open source project. I will post regular updates as a series of posts, as the journey unfolds.</description>
    </item>
    <item>
      <title>Running my dev.to blog using Hugo on Netlify</title>
      <link>https://blog.beachgeek.co.uk/hugo-site-migraiton/</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/hugo-site-migraiton/</guid>
      <description>Running my dev.to blog using Hugo on Netlify I am a big fan of dev.to, and the work that the team do to foster a great community of builders is something that keeps me there. I have always maintained another blog (running on Netlify, which is also super awesome), kind of like a mirror. Up until last year, I was able to publish to dev.to and it would take care of publishing to that mirror.</description>
    </item>
    <item>
      <title>Setting up MWAA to use a KMS key</title>
      <link>https://blog.beachgeek.co.uk/setting-up-mwaa-to-use-a-kms-key/</link>
      <pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/setting-up-mwaa-to-use-a-kms-key/</guid>
      <description>Introduction In a previous post, I shared how you can using AWS CDK to provision your Apache Airflow environments using the Managed Workflows for Apache Airflow service (MWAA).&#xA;I was contacted this week by Michael Grabenstein, who flagged an issue with the code in that post. The post used code that configured a kms key for the MWAA environment, but when trying to deploy the app it would fail with the following error:</description>
    </item>
    <item>
      <title>Integrating Amazon Timestream in your Amazon Managed Workflows for Apache Airflow v2.x</title>
      <link>https://blog.beachgeek.co.uk/integrating-amazon-timestream-in-your-amazon-managed-workflows-for-apache-airflow-v2x/</link>
      <pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/integrating-amazon-timestream-in-your-amazon-managed-workflows-for-apache-airflow-v2x/</guid>
      <description>Integrating with Amazon Timestream in your Apache Airflow DAGs&#xA;Amazon Timestream is a fast, scalable, and serverless time series database service perfect for use cases that generate huge amounts of events per day, optimised to make it faster and more cost effective that using relational databases.&#xA;I have been playing around with Amazon Timestream to prepare for a talk I am doing with some colleagues, and wanted to see how I could integrate it with other AWS services in the context of leveraging some of the key capabilities of Amazon Timestream.</description>
    </item>
    <item>
      <title>Reading and writing data across different AWS accounts with Amazon Managed Workflows for Apache Airflow v2.x</title>
      <link>https://blog.beachgeek.co.uk/reading-and-writing-data-across-different-aws-accounts-with-amazon-managed-workflows-for-apache-airflow-v2x/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/reading-and-writing-data-across-different-aws-accounts-with-amazon-managed-workflows-for-apache-airflow-v2x/</guid>
      <description>Reading and writing data across different AWS accounts in you Apache Airflow DAGs&#xA;As regular readers will know, I sometimes lurk in the Apache Airflow slack channel to see what is going on. If you are new to Apache Airflow, or want to get a deeper understanding then I highly recommend spending some time here. The community is super welcoming and eager to help new participants.&#xA;It was during a recent session I came across an interesting problem that one of the builders was having, which was how to access (read/write) data in an S3 bucket which was in a different account to the one hosting Amazon Managed Workflows for Apache Airflow (MWAA).</description>
    </item>
    <item>
      <title>Working with parameters and variables in Amazon Managed Workflows for Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/working-with-parameters-and-variables-in-amazon-managed-workflows-for-apache-airflow/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/working-with-parameters-and-variables-in-amazon-managed-workflows-for-apache-airflow/</guid>
      <description>Maximising the re-use of your DAGs in MWAA&#xA;During some recently conversations with customers, one of the topics that they were interested in was how to create re-usable, parameterised Apache Airflow workflows (DAGs) that could be executed dynamically through the use variables and/or parameters (either submitted via the UI or the command line). This makes a lot of sense, as you may find that you repeat similar tasks in your workflows, and so this approach allows you to maximise the re-use of that work.</description>
    </item>
    <item>
      <title>Creating a multi architecture CI/CD solution with Amazon ECS and ECS Anywhere</title>
      <link>https://blog.beachgeek.co.uk/creating-a-multi-architecture-cicd-solution-with-amazon-ecs-and-ecs-anywhere/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/creating-a-multi-architecture-cicd-solution-with-amazon-ecs-and-ecs-anywhere/</guid>
      <description>Please let me know how I can improve posts such as this one, by completing this very short survey. $25 AWS credits will be provided for the first 20 completed - take the survey&#xA;Organisations are moving their workloads to the cloud as quickly as they can. While most applications can be easily migrated to the cloud, some applications need to remain on-premises due to low-latency or data sovereignty requirements.</description>
    </item>
    <item>
      <title>Working with Amazon EKS and Amazon Managed Workflows for Apache Airflow v2.x</title>
      <link>https://blog.beachgeek.co.uk/working-with-amazon-eks-and-amazon-managed-workflows-for-apache-airflow-v2x/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/working-with-amazon-eks-and-amazon-managed-workflows-for-apache-airflow-v2x/</guid>
      <description>Introduction The Apache Airflow slack channel is a vibrant community of open source builders that is a great source of feedback, knowledge and answers to problems and use cases you might have when trying to do stuff with Apache Airflow. This week I picked up on someone seeing errors with Amazon EKS, and so I thought what better time to try out the new Apache Airflow 2.x version that was recently launched in Amazon Managed Workflows for Apache Airflow (MWAA).</description>
    </item>
    <item>
      <title>Working with the RedshiftToS3Transfer operator and Amazon Managed Workflows for Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/working-with-the-redshifttos3transfer-operator-and-amazon-managed-workflows-for-apache-airflow/</link>
      <pubDate>Sat, 15 May 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/working-with-the-redshifttos3transfer-operator-and-amazon-managed-workflows-for-apache-airflow/</guid>
      <description>Introduction Inspired by a recent conversation within the Apache Airflow open source slack community, I decided to channel the inner terrier within me to tackle this particular issue, around getting an Apache Airflow operator (the protagonist for this post) to work.&#xA;I found the perfect catalyst in the way of the original launch post of Amazon Managed Workflows for Apache Airflow (MWAA). As is often the way, diving into that post (creating a workflow to take some source files, transform them and then move them into Amazon Redshift) led me down some unexpected paths to here, this post.</description>
    </item>
    <item>
      <title>Using AWS CDK to deploy your Amazon Managed Workflows for Apache Airflow environment</title>
      <link>https://blog.beachgeek.co.uk/using-aws-cdk-to-deploy-your-amazon-managed-workflows-for-apache-airflow-environment/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/using-aws-cdk-to-deploy-your-amazon-managed-workflows-for-apache-airflow-environment/</guid>
      <description>update I am grateful to Michael Grabenstein for spotting some mistakes in the original post/code. I hope these have now been rectified in this post.&#xA;Using AWS CDK to deploy your Amazon Managed Workflows for Apache Airflow environment What better way to celebrate CDK Day than to return to a previous blog where I wrote about automating the installation and configuration of Amazon Managed Workflows for Apache Airflow (MWAA), and take a look at doing the same thing but this time using AWS CDK.</description>
    </item>
    <item>
      <title>Automating your ELT Workflows with Managed Workflows for Apache Airflow - Part One</title>
      <link>https://blog.beachgeek.co.uk/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow---part-one/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow---part-one/</guid>
      <description>update: I have changed the post to use standard Apache Airflow variables rather than using AWS Secrets Manager.&#xA;Part One - Automating Amazon Athena As part of an upcoming DevDay event, I have been working on how you can use Apache Airflow to help automate your Extract, Load and Transform (ELT) Workflows. Amazon Athena and Amazon EMR are two AWS services that help customers who have existing SQL skills/expertise and are looking at tools such as Presto or Apache Hive when undertaking those transformations.</description>
    </item>
    <item>
      <title>Automating your ELT Workflows with Managed Workflows for Apache Airflow - Part Two</title>
      <link>https://blog.beachgeek.co.uk/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow---part-two/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow---part-two/</guid>
      <description>Part Two - Automating Amazon EMR In Part One, we automated an example ELT workflow on Amazon Athena using Apache Airflow. In this post, Part Two, we will do the same thing but automate the same example ELT workflow using Amazon EMR.&#xA;Make sure you recap the setup from Part One. All the code so you can reproduce this yourself can be found in the GitHub repository here.&#xA;Automating Amazon EMR</description>
    </item>
    <item>
      <title>Monitoring and logging with Amazon Managed Workflows for Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/monitoring-and-logging-with-amazon-managed-workflows-for-apache-airflow/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/monitoring-and-logging-with-amazon-managed-workflows-for-apache-airflow/</guid>
      <description>Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow Part 2 - Working with Permissions Part 3 - Accessing Amazon Managed Workflows for Apache Airflow Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line Part 5 - A simple CI/CD system for your development workflow Part 6 - Monitoring and logging &amp;lt;- this post Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 6, where to find logs to help you understand and troubleshoot your Apache Airflow workflows, and how you can monitor your Apache Airflow environments.</description>
    </item>
    <item>
      <title>A simple CI/CD system for your Amazon Managed Workflows for Apache Airflow development workflow</title>
      <link>https://blog.beachgeek.co.uk/a-simple-cicd-system-for-your-amazon-managed-workflows-for-apache-airflow-development-workflow/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/a-simple-cicd-system-for-your-amazon-managed-workflows-for-apache-airflow-development-workflow/</guid>
      <description>updated Feb 19th&#xA;Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow Part 2 - Working with Permissions Part 3 - Accessing Amazon Managed Workflows for Apache Airflow Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line Part 5 - A simple CI/CD system for your development workflow &amp;lt;- this post Part 6 - Monitoring and logging Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 5, how you can setup a very simple CI/CD setup to enable faster development of your Apache Airflow DAGs.</description>
    </item>
    <item>
      <title>Interacting with Amazon Managed Workflows for Apache Airflow via the command line</title>
      <link>https://blog.beachgeek.co.uk/interacting-with-amazon-managed-workflows-for-apache-airflow-via-the-command-line/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/interacting-with-amazon-managed-workflows-for-apache-airflow-via-the-command-line/</guid>
      <description>Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow Part 2 - Working with Permissions Part 3 - Accessing Amazon Managed Workflows for Apache Airflow environments Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line &amp;lt; this post Part 5 - A simple CI/CD system for your development workflow Part 6 - Monitoring and logging Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 4, how you can interact and access the Apache Airflow via the command line.</description>
    </item>
    <item>
      <title>Accessing your Amazon Managed Workflows for Apache Airflow environments</title>
      <link>https://blog.beachgeek.co.uk/accessing-your-amazon-managed-workflows-for-apache-airflow-environments/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/accessing-your-amazon-managed-workflows-for-apache-airflow-environments/</guid>
      <description>Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow Part 2 - Working with Permissions Part 3 - Accessing Amazon Managed Workflows for Apache Airflow environments &amp;lt; this post Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line Part 5 - A simple CI/CD system for your development workflow Part 6 - Monitoring and logging Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 3, how you can interact and access the Apache Airflow environments.</description>
    </item>
    <item>
      <title>Working with permissions in Amazon Managed Workflows for Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/working-with-permissions-in-amazon-managed-workflows-for-apache-airflow/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/working-with-permissions-in-amazon-managed-workflows-for-apache-airflow/</guid>
      <description>Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow Part 2 - Working with Permissions &amp;lt;- this post Part 3 - Accessing Amazon Managed Workflows for Apache Airflow environments Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line Part 5 - A simple CI/CD system for your development workflow Part 6 - Monitoring and logging Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 2, how to ensure that you control access to Apache Airflow following best practices such as default no access/least privilege.</description>
    </item>
    <item>
      <title>Automating the installation and configuration of Amazon Managed Workflows for Apache Airflow</title>
      <link>https://blog.beachgeek.co.uk/automating-the-installation-and-configuration-of-amazon-managed-workflows-for-apache-airflow/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/automating-the-installation-and-configuration-of-amazon-managed-workflows-for-apache-airflow/</guid>
      <description>updated, August 25th Thanks to Philip T for spotting a typo in the cloudformation code below - it is ok in the GitHub repo, but I have fixed it now below.&#xA;Part of a series of posts to support an up-coming online event, the Innovate AI/ML on February 24th, from 9:00am GMT - you can sign up here&#xA;Part 1 - Installation and configuration of Managed Workflows for Apache Airflow &amp;lt;- this post Part 2 - Working with Permissions Part 3 - Accessing Amazon Managed Workflows for Apache Airflow environments Part 4 - Interacting with Amazon Managed Workflows for Apache Airflow via the command line Part 5 - A simple CI/CD system for your development workflow Part 6 - Monitoring and logging Part 7 - Automating a simple AI/ML pipeline with Apache Airflow In this post I will be covering Part 1, automating the installation and configuration of Managed Workflows for Apache Airflow (MWAA).</description>
    </item>
    <item>
      <title>TIL: Testing an Amazon Cloudwatch alarm</title>
      <link>https://blog.beachgeek.co.uk/til-testing-an-amazon-cloudwatch-alarm/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/til-testing-an-amazon-cloudwatch-alarm/</guid>
      <description>Today I was setting up an application load balancer that sits in front of a test application I have put together. Setting this up was super easy, and very quickly I had my domain pointing to the alias and serving requests.&#xA;As part of the setup, I wanted to monitor the application load balancer to let me know when requests were failing to the downstream application (anything other than an HTTP 200) and so I set this up super easily in Amazon Cloudwatch.</description>
    </item>
    <item>
      <title>Amazon Aurora - setting up and configuration, four ways</title>
      <link>https://blog.beachgeek.co.uk/amazon-aurora---setting-up-and-configuration-four-ways/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/amazon-aurora---setting-up-and-configuration-four-ways/</guid>
      <description>In this post I want to share four different approaches to installing and configuring your Amazon Aurora database clusters.&#xA;Everything in this post is covered in detail in the embedded video, but I wanted to share some additional information that I did not include in the video that was easier done in this blog.&#xA;{% youtube wZfh9PurE9E %}&#xA;Why four ways? The approach in the video was to look at the journey you might take when learning a new technology and then how you move to productise that technology.</description>
    </item>
    <item>
      <title>Long running data import jobs with AWS Session Manager</title>
      <link>https://blog.beachgeek.co.uk/long-running-data-import-jobs-with-aws-session-manager/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/long-running-data-import-jobs-with-aws-session-manager/</guid>
      <description>Yesterday I was looking to import the TPC-H dataset (some 600 or so million rows) into Amazon Aurora from a workstation that I connect to using AWS Session Manager.&#xA;AWS Session Manager is a great way to simplify your life by allowing you to connect to a machine via the AWS console and not worry about having to manage ssh keys or remembering to lock down external public access from the net.</description>
    </item>
    <item>
      <title>Building a culture of security in open source software development</title>
      <link>https://blog.beachgeek.co.uk/building-a-culture-of-security-in-open-source-software-development/</link>
      <pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/building-a-culture-of-security-in-open-source-software-development/</guid>
      <description>Updated on Jan 18th to remove broken link to report&#xA;According to a number of recent studies, the use and adoption of open source software continues to rise. From studies such as the State of Enterprise Open Source by Red Hat (in which nearly 70% of respondents stated that open source software is either extremely or very important) or TideLift’s April 2019 survey report (that found more than 90% of professional developers use open source in building their applications) it is clear that developers from startups to highly regulated enterprises have embraced open source solutions.</description>
    </item>
    <item>
      <title>Automating AWS SSO and G-Suite synchronisation with SSO Sync</title>
      <link>https://blog.beachgeek.co.uk/automating-aws-sso-and-g-suite-synchronisation-with-sso-sync/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/automating-aws-sso-and-g-suite-synchronisation-with-sso-sync/</guid>
      <description>update-July 28th The ssosync tool has had a lot of interest and the community has updated the tool. This means that you should refer to the project home page https://github.com/awslabs/ssosync and check out the README.md for what changes you might need to make to get this tool working.&#xA;Next level ssosync In a previous post, I talked about setting up AWS Single Sign On (AWS SSO) with G-Suite, and then using an open source project called ssosync to syncronise users and groups from G-Suite into AWS SSO.</description>
    </item>
    <item>
      <title>Setting up G-Suite, AWS SSO and ssosync</title>
      <link>https://blog.beachgeek.co.uk/setting-up-g-suite-aws-sso-and-ssosync/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/setting-up-g-suite-aws-sso-and-ssosync/</guid>
      <description>update-July 28th The ssosync tool has had a lot of interest and the community has updated the tool. This means that you should refer to the project home page https://github.com/awslabs/ssosync and check out the README.md for what changes you might need to make to get this tool working.&#xA;Enabling AWS SSO with Google G-Suite Many customers have existing directory technologies where they manage their users, and then use this central identity store as a way to simplify the way they authenticate and provide access to applications and other resources.</description>
    </item>
    <item>
      <title>Making the most of mentoring</title>
      <link>https://blog.beachgeek.co.uk/making-the-most-of-mentoring/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/making-the-most-of-mentoring/</guid>
      <description>Some recent experiences mentoring has provided the motivation for this piece. It is not intended to be right or wrong, but just my personal opinion and experience and I hope it is read that way. I have put this together to share what I think are the critical things that make a mentoring relationship work for both the mentor and mentee. So with that out of the way, I invite you to read on&amp;hellip;</description>
    </item>
    <item>
      <title>Mentoring and reverse mentoring</title>
      <link>https://blog.beachgeek.co.uk/mentoring-and-reverse-mentoring/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/mentoring-and-reverse-mentoring/</guid>
      <description>As I reflect on 2019, one of the common themes whilst engaging with builders at the start of their career, has been how do those of us who have deep experience working in the IT industry and technology help bring those who are just starting out?&#xA;Some common themes when talking that have come up include;&#xA;How do I get started on Cloud or AWS? What tools and languages should I learn?</description>
    </item>
    <item>
      <title>reInvent 2019 workshop list</title>
      <link>https://blog.beachgeek.co.uk/reinvent-2019-workshop-list/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/reinvent-2019-workshop-list/</guid>
      <description>So here is a list scraped from Twitter and following various other folk, of just a small taster of the workshops that ran during reInvent. As I find more I will update, and feel free to add yours in the comments (oh, and let me know if any of these are dead links)&#xA;Serverless - https://github.com/aws-samples/aws-serverless-workshop-innovator-island/ Serverless image process workshop - https://image-processing.serverlessworkshops.io/ Amplify preductions workshop - https://github.com/mlabieniec/IonicPredictions Full stack serverless Amplify lab - https://github.</description>
    </item>
    <item>
      <title>Make your business more resilient in the digital age</title>
      <link>https://blog.beachgeek.co.uk/make-your-business-more-resilient-in-the-digital-age/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/make-your-business-more-resilient-in-the-digital-age/</guid>
      <description>Very humbled to write a guest post on Adrian Hornsby excellent blog where he provides guidance to help customers build resilient architecture and champions operational excellence.&#xA;In this post I talk about what you need to think about to build a more resilient business fit for the digital age.&#xA;Here is the link: https://medium.com/@adhorn/make-your-business-more-resilient-in-the-digital-age-888da3f5deaf</description>
    </item>
    <item>
      <title>Innovate Machine Learning and AI - learn how to kick start your journey</title>
      <link>https://blog.beachgeek.co.uk/innovate-machine-learning-and-ai---learn-how-to-kick-start-your-journey/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://blog.beachgeek.co.uk/innovate-machine-learning-and-ai---learn-how-to-kick-start-your-journey/</guid>
      <description>On October 17th we have a free, online event covering several tracks on Machine Learning. Whether you are a complete beginner or seasoned data scientist, we have gentle introductions to deep dives.&#xA;What I am most excited about however, is that we will have an AWS DeepRacer racing challenge. You will learn how to create your first reinforcement learning model that will race a virtual car, with prizes for the fastest times.</description>
    </item>
  </channel>
</rss>
